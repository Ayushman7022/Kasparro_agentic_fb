Overview

This document describes the multi-agent architecture of the Kasparro FB Ads Intelligence System.
The system uses a fully modular agentic workflow to:

Break down a user query into actionable analytical tasks

Generate hypotheses from tasks

Validate them using statistical & quantitative evaluation

Trigger creative generation when needed

Produce structured insights, creatives, and a full analytical report

This file visualizes the information flow, dependencies, and agent interaction graph.

ğŸ§  High-Level Architecture Diagram
flowchart TD

A[User Query] --> B[Planner Agent]

B -->|Task List| C[Insight Agent]

C -->|Hypotheses| D[Evaluator Agent]

D -->|Validation Results| H[Report Builder]

D -->|If VALIDATED & driver=creative_fatigue| E[Creative Agent]

E -->|Generated Creatives| H[Report Builder]

subgraph Data Layer
F[DataAgent] --> C
F --> D
end

H --> I[Final Outputs: insights.json, creatives.json, report.md, metadata.json]

ğŸ—‚ï¸ Agent Responsibilities
1. Planner Agent

ğŸ¯ Goal: Convert a natural-language query into a structured, multi-step analytical plan.

Inputs:

User query (text)

Data summary (from DataAgent)

Outputs:

List of tasks (TaskSchema), each with:

id

name

type

target metric

scope

priority

depends_on

output schema

ğŸ§  The planner sets the reasoning structure for the entire system.

2. Insight Agent

ğŸ¯ Goal: Generate hypotheses for each planned task using LLM reasoning.

Inputs:

Task description

Data summary

Outputs:

List of hypotheses (Hypothesis model):

hypothesis text

driver (creative_fatigue, roas_drop, ctr_drop, etc.)

initial confidence

required checks

supporting datapoints

ğŸ§ª This agent is the systemâ€™s intelligent inference module.

3. Evaluator Agent

ğŸ¯ Goal: Validate each hypothesis with real statistical techniques.

Inputs:

Hypothesis

DataAgent to fetch timeseries

Methods used:

Welch t-test

Bootstrap p-value

Cohenâ€™s d effect size

Relative % change

Change-point detection

Confidence recalibration

Outputs:

ValidationResult:

status â†’ VALIDATED / REFUTED / INCONCLUSIVE

p-value

effect size

relative change

confidence_final

notes

ğŸ“Š This agent ensures LLM claims are quantitatively grounded.

4. Creative Agent

ğŸ¯ Goal: Generate fresh, deduplicated creatives when evaluator confirms creative fatigue.

Inputs:

campaign scope

sample creatives

number of variations needed

Outputs:

JSON creatives:

headline

body

CTA

rationale

creative_type

creative_id

ğŸ¨ This agent extends the insight pipeline into actionable creative strategy.

5. Data Agent

ğŸ¯ Goal: The factual reference. Provides clean data to all agents.

Provides:

Dataset summary

Time-series (CTR/ROAS/Spends)

Creative samples

Grouped stats

ğŸ“š Acts as the data layer of the system.

ğŸ”„ Detailed Workflow
sequenceDiagram
    participant U as User
    participant O as Orchestrator
    participant P as PlannerAgent
    participant D as DataAgent
    participant I as InsightAgent
    participant V as EvaluatorAgent
    participant C as CreativeAgent
    participant R as ReportBuilder

    U->>O: Provide query
    O->>D: Request data summary
    D-->>O: Summary
    O->>P: Build task plan
    P-->>O: Task list

    loop For each Task
        O->>I: Generate hypotheses
        I-->>O: Hypothesis list

        loop For each Hypothesis
            O->>V: Validate hypothesis
            V-->>O: ValidationResult

            alt Validated & driver=creative_fatigue
                O->>C: Generate creatives
                C-->>O: Creative set
            end
        end
    end

    O->>R: Create JSON + Markdown reports
    R-->>U: insights.json, creatives.json, report.md

ğŸ§© Key Agent Interactions
Planner â†’ Insight (Task decomposition â†’ Hypotheses)

Planner outputs â€œwhat to checkâ€.
Insight outputs â€œwhy this may be happeningâ€.

Insight â†’ Evaluator (Hypotheses â†’ Math validation)

Evaluator tests every hypothesis using real data.

Evaluator â†’ CreativeAgent (Decision-triggered generation)

Only when:

status == "VALIDATED"
AND driver == "creative_fatigue"

Orchestrator controls entire pipeline

Acts as the â€œconductorâ€ that sequences every agent intelligently.

ğŸ—ƒï¸ Artifacts Produced

The system outputs:

reports/
â”‚â”€â”€ insights_<run_id>.json
â”‚â”€â”€ creatives_<run_id>.json
â”‚â”€â”€ report_<run_id>.md
â”‚â”€â”€ run_metadata_<run_id>.json


Plus runtime logs in:

logs/

ğŸ Conclusion

This multi-agent architecture follows the exact structure required by the Kasparro assignment:

Structured agent roles

Planner â†’ Insight â†’ Evaluator loop

Creative generation only when validated

Modular, interpretable, extensible pipeline

Fully aligned with the evaluation rubric

The graph and workflow below prove the usage of a true agentic system rather than a monolithic script.